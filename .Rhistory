test_that("str_length is number of characters", {
expect_that(str_length("a"), equals(1))
expect_that(str_length("ab"), equals(2))
expect_that(str_length("abc"), equals(3))
## Jacob Hample
## Professor Montgomery
## Applied Statistical Programming
## March 10, 2016
### Problem Set 5 ###
# Sets working directory
setwd("~/Google Drive/Senior Year/Spring 2016/Statistical Programming/Problem Sets/PS5")
# Sets seed so that randomization is constant
set.seed(12435)
# Keeps inputted strings from being categorized as factors
options(stringsAsFactors = FALSE)
# Additional packages used
library(foreign)
# Reads in data
anes <- read.dta("anes_timeseries_2012_stata12.dta")
### Question 1
## Selecting and Cleaning Variables
# DEPENDENT VARIABLE: ft_dpc
# Description:
# Feeling Thermometer, Democratic Presidential Candidate
# Replaces negative thermometer ratings with NAs
anes$ft_dpc <- ifelse(anes$ft_dpc < 0, NA, anes$ft_dpc)
# INDEPENDENT VARIABLE 1: finance_finpast
# Question posed:
# We are interested in how people are getting along financially these days.
# Would you say that [you/you and your family living here] are BETTER off or
# WORSE off than you were a year ago?
# Recodes finance_finpast to make it more legible and replaces missing responses with NAs
anes$finance_finpast <- as.factor(ifelse(anes$finance_finpast == "1. Better", "1. Better",
ifelse(anes$finance_finpast == "2. Worse", "2. Worse",
ifelse(anes$finance_finpast == "3. The same {VOL}", "3. Same",
NA))))
# INDEPENDENT VARIABLE 2 : finance_finnext
# Question posed:
# Now looking ahead, do you think that a year from now
# [you / you and your family living here] will be BETTER OFF financially,
# WORSE OFF, or JUST ABOUT THE SAME as now?
# Recodes finance_finnext to make it more legible and replaces missing responses with NAs
anes$finance_finnext <- as.factor(ifelse(anes$finance_finnext == "1. Better", "1. Better",
ifelse(anes$finance_finnext == "2. Worse", "2. Worse",
ifelse(anes$finance_finnext == "3. The same", "3. Same",
NA))))
# INDEPENDENT VARIABLE 3: dem_edugroup_x
# Description:
# PRE: SUMMARY- R level of highest education (group)
# Replaces missing responses with NAs
anes$dem_edugroup_x <- as.factor(ifelse(anes$dem_edugroup_x == "1. Less than high school credential", "1. Less than high school credential",
ifelse(anes$dem_edugroup_x == "2. High school credential", "2. High school credential",
ifelse(anes$dem_edugroup_x == "3. Some post-high-school, no bachelor's degree", "3. Some post-high-school, no bachelor's degree",
ifelse(anes$dem_edugroup_x == "4. Bachelor's degree", "4. Bachelor's degree",
ifelse(anes$dem_edugroup_x == "5. Graduate degree", "5. Graduate degree",
NA))))))
# INDEPENDENT VARIABLE 4: dem2_numchild
# Description:
# Total Number of children in HH
# Recodes dem2_numchild as a dummy variable for presence of children and replaces missing responses with NAs
anes$dem2_numchild <- as.numeric(ifelse(anes$dem2_numchild == "0. No children in household", 0,
ifelse(anes$dem2_numchild == "1. One child in household", 1,
ifelse(anes$dem2_numchild == "2. Two children in household", 1,
ifelse(anes$dem2_numchild == "3. Three or more children in household", 1,
NA)))))
# INDEPENDENT VARIABLE 5: health_insured
# Question posed:
# Do you presently have any kind of health insurance?
# Recodes health_insured as a dummy variable and replaces missing responses with NAs
anes$health_insured <- as.numeric(ifelse(anes$health_insured == "1. Yes", 1,
ifelse(anes$health_insured == "2. No", 0,
NA)))
# INDEPENDENT VARIABLE 6: interest_attention
# Question posed:
# How often do you pay attention to what's going on in government and politics?
# [ALWAYS, MOST OF THE TIME, ABOUT HALF THE TIME, SOME OF THE TIME, or NEVER /
# NEVER, SOME OF THE TIME, ABOUT HALF THE TIME, MOST OF THE TIME, or ALWAYS]?
# Replaces missing responses with NAs
anes$interest_attention <- as.factor(ifelse(anes$interest_attention == "1. Always", "1. Always",
ifelse(anes$interest_attention == "2. Most of the time", "2. Most of the time",
ifelse(anes$interest_attention == "3. About half the time", "3. About half the time",
ifelse(anes$interest_attention == "4. Some of the time", "4. Some of the time",
ifelse(anes$interest_attention == "5. Never", "5. Never",
NA))))))
# INDEPENDENT VARIABLE 7: relig_import
# Question posed:
# Do you consider religion to be an IMPORTANT part of your life, or NOT?
# Recodes relig_import variable as a dummy variable and replaces missing responses with NAs
anes$relig_import <- as.numeric(ifelse(anes$relig_import == "1. Important", 1,
ifelse(anes$relig_import == "2. Not important", 0,
NA)))
# INDEPENDENT VARIABLE 8: dem_racecps_black
# Description: PRE:
# Race self-identification: mention Black
# Recodes dem_racecps_black as a dummy variable and replaces missing responses with NAs
anes$dem_racecps_black <- as.numeric(ifelse(anes$dem_racecps_black == "0. Not selected by R", 0,
ifelse(anes$dem_racecps_black == "1. Selected by R", 1,
NA)))
# INDEPENDENT VARIABLE 9: dem_veteran
# Question posed:
# Did you ever serve on active duty in the U. S. Armed Forces?
# Recodes dem_veteran as a dummy variable and replaces missing responses with NAs
anes$dem_veteran <- as.numeric(ifelse(anes$dem_veteran == "1. Yes", 1,
ifelse(anes$dem_veteran == "2. No", 0,
NA)))
## Splitting Data
# Separates dataset into training and test halves
train <- sample(dim(anes)[1], dim(anes)[1] / 2, replace = FALSE)
training.anes <- anes[train, ]
test.anes <- anes[-train, ]
## Creating Models
# Obama's feeling thermometer score as a function of past financial results, financial optimism, and education level
model1 <- lm(ft_dpc ~ finance_finpast + finance_finnext + dem_edugroup_x, training.anes)
model1
# Obama's feeling thermometer score as a function of presence of children, presence of health insurance, and political interest level
model2 <- lm(ft_dpc ~ dem2_numchild + health_insured + interest_attention, training.anes)
model2
# Obama's feeling thermometer score as a function of religious importance, race, and military experience
model3 <- lm(ft_dpc ~ relig_import + dem_racecps_black + dem_veteran, training.anes)
model3
### Question 2
# Predicts each model using the test data and stores the predictions in vectors
predict1 <- c(as.numeric(predict(model1, data = test.anes)))
predict2 <- c(as.numeric(predict(model2, data = test.anes)))
predict3 <- c(as.numeric(predict(model3, data = test.anes)))
# Combines predictions of each model into a data frame
predictALL <- data.frame(cbind(predict1, predict2, predict3))
# Unfortuantely, since the three vectors that make up predictALL are different lengths,
# when they are combined, missing values after the conclusion of the shorter vectors
# are automatically replaced with the first, then second, then third, etc. values
# of said vector. This is can cause some problems, so we're going to have to go back and
# replace these extra values with NAs.
# Replaces duplicate values in columns 1 & 3 with NAs
for (i in (length(predict1) + 1):length(predictALL[, 1])) {
predictALL[i, 1] <- NA
}
for (i in (length(predict3) + 1):length(predictALL[, 3])) {
predictALL[i, 3] <- NA
}
a <- c(100, 200, 300)
which(a == 200)
1:25
(1:25)^2
## 4625 - R Programming
## March 24, 2016
## Improving code
rm(list=ls())
## Chapter 16 in Advanced R provides some philosophical discussion regarding
## the distinction between R as both a language and as an implementation of
## that language. While interesting and helpful, we will focus on some more
## applied work today.
## Three main topics: benchmarking, vectorizing, parallel
## Benchmarking allows you to measure the time that functions take to be executed
## Easy approach: system.time
x <- runif(500)
system.time(sqrt(x))
## The values presented (user, system, and elapsed) will be defined by your
## operating system, but generally, the user time relates to the execution of
## the code, the system time relates to your CPU, and the elapsed time is the
## difference in times since you started the stopwatch (and will be equal to
## the sum of user and system times if the chunk of code was run altogether).
system.time(replicate(100000,sqrt(x)))
install.packages("microbenchmark")
## Much better than system.time: microbenchmark
#install.packages("microbenchmark")
library(microbenchmark)
?microbenchmark
microbenchmark(sqrt(x)) # evalues 100 times per default
microbenchmark(sqrt(x), times=1000)
## Now we can compare different functions
microbenchmark(sqrt(x),
x^0.5,
times=1000)
microbenchmark(sqrt(x), x^0.5, x^(1/2), exp(log(x)/2),
times=1000)
## And also completely different functions
microbenchmark(sqrt(x), x^4-3*x)
## For ease of interpretation, if a microbenchmark takes
## 1 millisecond, then 1,000 calls take a second
## 1 microsecond, then 1,000,000 calls take a second
## 1 nanosecond,  then 1,000,000,000 calls take a second
microbenchmark(sqrt(x))
microbenchmark(1+2)
## Or use unit=eps for evaluations per second
microbenchmark(sqrt(x), x^0.5, x^(1/2), exp(log(x)/2),
unit="eps")
## Evaluating every function takes time
## Evaluating () or {} takes time
## Even specifying useless arguments in functions takes time!
f0 <- function() NULL
f1 <- function(a=1) NULL
f2 <- function(a=1, b=2) NULL
f3 <- function(a=1, b=2, c=3) NULL
f4 <- function(a=1, b=2, c=3, d=4) NULL
f5 <- function(a=1, b=2, c=3, d=4, e=5) NULL
microbenchmark(f0(), f1(), f2(), f3(), f4(), f5(), times=10000)
## There is room for improvement (or mistakes) in the most basic functions!
## Extracting one element of a data frame
?mtcars
head(mtcars)
microbenchmark(
"[32, 11]" = mtcars[32,11],
"$carb[32]"	= mtcars$carb[32],
"[[c(11, 32)]]" = mtcars[[c(11,32)]],
"[[11]][32]" = mtcars[[11]][32],
".subset2" = .subset2(mtcars,11)[32])
.subset2(mtcars,11)[32]
microbenchmark(4^2 + 5^2)
library(squaresPack)
addSquares(4,5)
microbenchmark(4^2 + 5^2, addSquares(4, 5))
s3.addSquares <- function (x, y) {
square <- x^2 + y^2
}
microbenchmark(4^2 + 5^2, addSquares(4, 5), s3.addSquares(4,5))
microbenchmark(4^2 + 5^2, s3.addSquares(x, y), addSquares(4, 5))
microbenchmark(4^2 + 5^2, s3.addSquares(4, 5), addSquares(4, 5))
library(devtools)
devtools::install_github("hadley/lineprof")
library(lineprof)
source("~/Desktop/pause.R")
source("/Users/Jacob/Google Drive/Senior Year/Spring 2016/Statistical Programming/Lectures/pause.R")
source("/Users/Jacob/Google Drive/Senior Year/Spring 2016/Statistical Programming/Lectures/Lecture11_pause.R")
prof <- lineprof(f())
prof
source("~/Google Drive/Senior Year/Spring 2016/Statistical Programming/Lectures/Lecture11_pause.R")
## Use shiny package for visual inspection
shine(prof)
## Examples
## Addition on each element of a data frame
rm(list=ls())
m=5
n=5
matrix1 <- replicate(m, rnorm(n)) # create matrix
matdf <- matdf1 <- matdf2 <- data.frame(matrix1) # transform into data frame
matdf
for (i in 1:m) {
for (j in 1:n) {
matdf1[i,j] <- matdf1[i,j] + 1.87*cos(.25)*pi # addition
}
}
matdf1
matdf2 <- matdf2 + 1.87*cos(.25)*pi
matdf2
microbenchmark(
"loop" = for (i in 1:m) {
for (j in 1:n) {
matdf[i,j] <- matdf[i,j] + 1.87*cos(.25)*pi
}
},
"vectorized" = matdf <- matdf + 1.87*cos(.25)*pi
)
library(parallel)
cores <- detectCores()
cores
## On a Mac:
pause <- function(i) {
function(x) Sys.sleep(i)
}
microbenchmark(
lapply(1:4, pause(0.25)),
mclapply(1:4, pause(0.25), mc.cores = cores),
times=10
)
## More generally with apply/plyr family
library(plyr)
bigmat <- matrix(rnorm(90000), ncol=300)
dim(bigmat)
library(doMC)
registerDoMC(4) # register number of cores
microbenchmark(
"solo" = aaply(bigmat, 2, sum),
"parallel" = aaply(bigmat, 2, sum, .parallel=T),
times=20
)
## But of course we now know that this should really be colSums
microbenchmark(
"solo" = aaply(bigmat, 2, sum),
"parallel" = aaply(bigmat, 2, sum, .parallel=T),
"vectorized" = colSums(bigmat),
times=20
)
fib <- c()
Fib <- sapply(3:n) function(i) {
fib <- c(rep(NA), n)
fib[1:2] <- 1
fib[i] <- fib[i-2] + fib[i-2]
}
Fib <- function(n) {
sapply(3:n) function(i) {
fib <- c(rep(NA), n)
fib[1:2] <- 1
fib[i] <- fib[i-2] + fib[i-2]
}
}
Fib <- function(n) {
fib <- c(rep(NA), n)
fib[1:2] <- 1
sapply(3:n) function(i) {
fib[i] <- fib[i-2] + fib[i-2]
}
}
Fib <- function(n) {
fib <- c(rep(NA), n)
fib[1:2] <- 1
sapply(3:n) function(i) fib[i] <- fib[i-2] + fib[i-2]
}
Fib <- function(n) {
fib <- c(rep(NA), n)
fib[1:2] <- 1
sapply(3:n, function(i) fib[i] <- fib[i-2] + fib[i-2]
}
Fib <- function(n) {
fib <- c(rep(NA), n)
fib[1:2] <- 1
sapply(3:n, function(i) fib[i] <- fib[i-2] + fib[i-2])
}
Fib(10)
Fib <- function(n) {
fib <- c(rep(NA), n)
fib[1:2] <- 1
sapply(3:n, function(i) fib[i] <- fib[i-1] + fib[i-2])
}
Fib(10)
fib <- c(rep(NA), 10)
fib[1:2] <- 1
sapply(3:10, function(i) fib[i] <- fib[i-1] + fib[i-2])
fib <- c(rep(NA), 10)
fib
fib <- rep(NA, 10)
fib <- rep(NA, 10)
fib
fib[1:2] <- 1
fib
sapply(3:10, function(i) fib[i] <- fib[i-1] + fib[i-2])
fib
sapply(3:10, function(i) {
fib <- rep(NA, 10)
fib[1:2] <- 1
fib[i] <- fib[i-1] + fib[i-2]
}
fib
fib
sapply(3:10, function(i) {
fib <- rep(NA, 10)
fib[1:2] <- 1
fib[i] <- fib[i-1] + fib[i-2]
}
)
sapply(3:10, function(i) {
fib <- rep(NA, 10)
fib <- fib[1:2] = 1
fib[i] <- fib[i-1] + fib[i-2]
}
)
sapply(3:10, function(i) {
fib[i] <- fib[i-1] + fib[i-2]
}
)
Fib <- function(n) {
fib <- rep(NA, n)
fib[1:2] <- 1
sapply(3:n, function(i) {
fib[i] <- fib[i-1] + fib[i-2]
}
)
}
Fib(10)
library(sfsmisc)
library(cubature)
library(pracma)
library(lattice)
### We want to integrate this function
mixDist <- function(x){
(.8*dnorm(x, mean=1, sd=1)+.2*dnorm(x, mean=-1, sd=.4))
}
### What does it look like?
curve(from=-3, to=4, mixDist, n=1000)
### What is the area under the curve between -2 and 2?
ans <- .8*(pnorm(2, mean=1, sd=1)-pnorm(-2, mean=1, sd=1))+
.2*(pnorm(2, mean=-1, sd=.4)-pnorm(-2, mean=-1, sd=.4))
ans
### Let's draw that
segments(-2, 0, -2, mixDist(-2), lwd=2)
segments(2, 0, 2, mixDist(2), lwd=2)
cord.x <- c(-2,seq(-2,2,0.01),2)
cord.y <- c(0,mixDist(seq(-2,2,0.01)),0)
polygon(cord.x,cord.y,col='skyblue')
##### Let's try a couple of different methods to integrate this
## Trapezoids
n <- 101
x <- seq(-2, 2, len = n)
y <- mixDist(x)
trapz(x, y)
trapz(x, y)-ans
integrate(mixDist, -2, 2)
integrate(mixDist, -2, 2)$value -ans
### Fixed Gauss-Hermite quadrature
points <- seq(from=-2, to=2, length=40)
integrate.xy(points, mixDist(points))
integrate.xy(points, mixDist(points))-ans
### Monte Carlo Integration
mcInt <- function(ftn, a, b, n){
u <- runif(n, a, b)
x <- sapply(u, ftn)
return(mean(x)*(b-a))
}
mcInt(mixDist, -2, 2, 10000)
mcInt(mixDist, -2, 2, 10000)-ans
##### Now let's add dimensions
dimensions=2
ndraws=1000
vals <- matrix(rnorm(2*1000), ncol=dimensions, nrow=ndraws)
library(mvtnorm)
probs <- dmvnorm(vals, mean=rep(0, dimensions), sigma=diag(rep(1, dimensions)))
total <- data.frame(cbind(probs, vals))
colnames(total) <- (c("probs", "V1", "V2"))
cloud(probs~V1*V2, data=total)
###
myNorm <- function(x){
dmvnorm(x, mean=rep(0, dimensions), sigma=diag(rep(1, dimensions)))
}
## Calculate the actual answer
ans <- pmvnorm(upper=rep(.5, dimensions), mean=rep(0, dimensions), sigma=diag(rep(1, dimensions)))
ans <- as.numeric(ans)
ans
## Quadrature again
adaptIntegrate(myNorm, lowerLimit=rep(-100, dimensions), upperLimit=rep(.5, dimensions))
adaptIntegrate(myNorm, lowerLimit=rep(-100, dimensions), upperLimit=rep(.5, dimensions))$integral -ans
install.packages("mvtnorm")
dimensions=2
ndraws=1000
vals <- matrix(rnorm(2*1000), ncol=dimensions, nrow=ndraws)
library(mvtnorm)
probs <- dmvnorm(vals, mean=rep(0, dimensions), sigma=diag(rep(1, dimensions)))
total <- data.frame(cbind(probs, vals))
colnames(total) <- (c("probs", "V1", "V2"))
cloud(probs~V1*V2, data=total)
###
myNorm <- function(x){
dmvnorm(x, mean=rep(0, dimensions), sigma=diag(rep(1, dimensions)))
}
## Calculate the actual answer
ans <- pmvnorm(upper=rep(.5, dimensions), mean=rep(0, dimensions), sigma=diag(rep(1, dimensions)))
ans <- as.numeric(ans)
ans
## Quadrature again
adaptIntegrate(myNorm, lowerLimit=rep(-100, dimensions), upperLimit=rep(.5, dimensions))
adaptIntegrate(myNorm, lowerLimit=rep(-100, dimensions), upperLimit=rep(.5, dimensions))$integral -ans
### Monte Carlo Integration
mcInt <- function(ftn, a, b, n, dimensions){
u <- runif(n*dimensions, a, b)
these <- matrix(u, ncol=dimensions)
x <- apply(these,1, ftn)
return(mean(x)*(b-a)^dimensions)
}
mcInt(myNorm, -4, .5, n=100000, dimensions=2)-ans
install.packages("EMBAforecast")
install.packages("EMBAforecast")
install.packages("EMBAforecast")
install.packages("EBMAforecast")
library(EBMAforecast)
library(EBMAforecast)
remove.packages("EBMAforecast")
# Jacob Hample
# Professor Montgomery
# Applied Statistical Programming
# Midterm Exam
library(devtools)
library(roxygen2)
# devtools
current.code <- as.package("integrateIt")
load_all(current.code)
document(current.code)
# Creates vectors containing x & y values of a mathematical function
x <- seq(1, 25, length.out = 25)
y <- (x-10)^2 + 5
# S3 Trapezoidal Rule
trap <- function(x, y, a, b) {
n <- length(x) - 1
h <- (x[length(x)] - x[1]) / n
X <- seq(a, b, by = h)
y.indices <- which(round(x, 5) %in% round(X, 5))
Y <- y[y.indices]
n <- length(X) - 1
estInt <- h/2 * (Y[1] + sum(2*Y[2:n]) + Y[n+1])
return(estInt)
}
trap(x, y, 4, 22)
# Print method
print.trap <- function(x, y, a, b) {
estInt <- trap(x, y, a, b)
print(estInt)
}
print.trap(x, y, 4, 22)
library(devtools)
library(roxygen2)
setwd("~/Desktop/integrateIt_revised")
current.code <- as.package("integrateItRevised")
package.skeleton("integrateItRevised")
rm(list=ls())
current.code <- as.package("integrateItRevised")
load_all(current.code)
document(current.code)
library(devtools)
library(roxygen2)
setwd("~/Desktop/integrateItRevised")
package.skeleton("integrateItRevised")
rm(list=ls())
current.code <- as.package("integrateItRevised")
load_all(current.code)
document(current.code)
